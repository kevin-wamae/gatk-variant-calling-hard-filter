# #####################################################################
#   A Snakemake pipeline for variant calling from illumina sequences
# #####################################################################

# TODO: include snakemake reports - https://snakemake.readthedocs.io/en/v5.32.0/snakefiles/reporting.html#snakefiles-reports
# TODO: abide by https://snakemake.readthedocs.io/en/v5.32.0/snakefiles/deployment.html#

# table of contents
# *********************************************************************
# step 1 - output files
# - 1) rule all - gather all output files

# step 2 - gather genome data
# - 2a) rule gather_genome_data - download and aggregate genome data
# - 2b) rule gatk_genome_dict - create genome dictionary
# - 2c) rule samtools_index - index genome fasta file
# - 2d) rule bedops_gff2bed - convert genome annotation gff to bed

# step 3 - quality control
# -  3) rule trim_reads - trim adapters and low quality bases

# step 4 - map reads to genome
# - 4a) rule bwa_index - generate bwa genome-index files for mapping
# - 4b) rule bwa_mem - map reads to genome
# - 4c) rule gatk_clean_bam - clean sam file (remove artifacts in SAM/BAM files)
# - 4d) rule samtools_fixmate - fix mate information
# - 4e) rule gatk_markdup - mark duplicate reads
# - 4f) rule samtools_filter - filter reads occurring in the core genome and index the bam file

# step 5 - mapping quality statistics
# - 5a) rule samtools_idxstats - count reads in each chromosome
# - 5b) rule samtools_flagstats - count reads in each chromosome
# - 5c) rule gatk_insert_size_metrics - collect insert size metrics

# step 6 - variant calling
# - 6a) rule gatk_haplotypecaller - call snps and indels via local re-assembly of haplotypes
# - 6b) rule generate_sample_name_map - generate a map of sample names to vcf files
# - 6c) rule gatk_genomics_db_import - merge gVCFs into one genomic database
# - 6d) rule gatk_genotype_gvcfs - perform joint genotyping

# step 7 - variant filtering
# - 7a) rule gatk_split_variants - separate snps and indels
# - 7b) rule gatk_filter_hard - snps and indels
# - 7c) rule gatk_merge_vcfs - merge snps and indels
# - 7d) rule gatk_filter_pass - exclude variants that failed filters

# step 8 - variant annotation
# - 8a) rule snpeff_annotate_variants - variant annotation and functional effect prediction
# - 8b) rule snpsift - extract vcf fields and calculate allele frequencies


# ######################################################################
#                              Dependencies
# ######################################################################
# configuration file
configfile: "config/config.yaml"


# generate a list of sample names
(SAMPLES,) = glob_wildcards(config["input"]["fastq"] + "{sample}_R1.fastq.gz")


# ######################################################################
#               Step 1 - Prepare a list of all output files
# ######################################################################


# 1) gather all output files
# *********************************************************************
rule all:
    input:
        # ------------------------------------
        # gather_genome_data
        config["gather_genome_data"]["fasta"],
        config["gather_genome_data"]["gff"],
        # ------------------------------------
        # genome_dict
        config["gather_genome_data"]["dict"],
        # config["gather_genome_data"]["regions"],
        # ------------------------------------
        # samtools_index
        config["samtools_index"]["fasta_idx"],
        # ------------------------------------        
        # bedops_gff2bed
        config["bedops_gff2bed"]["bed"],
        # ------------------------------------
        # trimmomatic/fastp,
        expand(
            config["trim_reads"]["dir"] + "paired/{sample}_R1.trimmed.fastq.gz",
            sample=SAMPLES,
        ),
        expand(
            config["trim_reads"]["dir"] + "paired/{sample}_R2.trimmed.fastq.gz",
            sample=SAMPLES,
        ),
        expand(
            config["trim_reads"]["dir"] + "unpaired/{sample}_R1.unpaired.fastq.gz",
            sample=SAMPLES,
        ),
        expand(
            config["trim_reads"]["dir"] + "unpaired/{sample}_R2.unpaired.fastq.gz",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # bwa_index
        config["bwa"]["index"],
        # ------------------------------------
        # bwa_mem
        expand(config["bwa"]["dir"] + "{sample}.bam", sample=SAMPLES),
        # ------------------------------------
        # gatk_clean_bam
        expand(config["gatk_clean_bam"]["dir"] + "{sample}.bam", sample=SAMPLES),
        # ------------------------------------
        # samtools_fixmate
        expand(config["samtools_fixmate"]["dir"] + "{sample}.bam", sample=SAMPLES),
        # ------------------------------------
        # gatk_markdup
        expand(config["gatk_markdup"]["dir"] + "{sample}.bam", sample=SAMPLES),
        expand(
            config["gatk_markdup"]["metrics"] + "{sample}.metrics.txt", sample=SAMPLES
        ),
        # ------------------------------------
        # samtools_filter
        expand(config["samtools_filter"]["dir"] + "{sample}.bam", sample=SAMPLES),
        expand(config["samtools_filter"]["dir"] + "{sample}.bam.bai", sample=SAMPLES),
        # ------------------------------------
        # samtools_idxstats
        expand(
            config["map_qual_stats"]["dir"]
            + "samtools/idxstats/{sample}.bam.idxstats.txt",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # samtools_flagstats
        expand(
            config["map_qual_stats"]["dir"]
            + "samtools/flagstat/{sample}.bam.flagstat.txt",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # samtools_depth
        expand(
            config["map_qual_stats"]["dir"] + "samtools/depth/{sample}.bam.depth.txt",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # gatk_insert_size_metrics
        expand(
            config["map_qual_stats"]["dir"]
            + "gatk/insert_size/metrics/{sample}.metrics.txt",
            sample=SAMPLES,
        ),
        expand(
            config["map_qual_stats"]["dir"]
            + "gatk/insert_size/histogram/{sample}.histogram.pdf",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # gatk_realign
        expand(
            config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # gatk_haplotypecaller
        expand(
            config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # generate_sample_name_map
        config["vcf_sample_name_map"]["tsv"],
        # ------------------------------------
        # gatk_genomics_db_import
        config["gatk_genomicsdb"]["dir"],
        # ------------------------------------
        # gatk_genotype_gvcfs
        expand(
            config["gatk_genotype_gvcfs"]["dir"] + "genotypes.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # gatk_split_variants
        config["gatk_var_split"]["dir"] + "snps.vcf.gz",
        config["gatk_var_split"]["dir"] + "indels.vcf.gz",
        # ------------------------------------
        # gatk_variant_filtration
        config["gatk_filter_hard"]["dir"] + "snps_filtered.vcf.gz",
        config["gatk_filter_hard"]["dir"] + "indels_filtered.vcf.gz",
        # ------------------------------------
        # gatk_merge_vcfs
        config["gatk_merge_vcfs"]["dir"] + "merged.vcf.gz",
        # ------------------------------------
        # gatk_filter_pass
        config["gatk_filter_pass"]["dir"] + "pass.vcf.gz",
        # ------------------------------------
        # snpeff_annotate_variants
        config["snpeff"]["dir"] + "annotated.vcf.gz",
        # ------------------------------------
        # snpsift_extract_variants
        config["snpeff"]["dir"] + "annotated.tsv",
        # ------------------------------------


# ######################################################################
#                      Step 2 - Gather Genome Data
# ######################################################################


# TODO: include temp dir (e.g  scratch space) for gatk tools


# 2a) genome data - download genome data
# *********************************************************************
rule gather_genome_data:
    input:
        genome=config["input"]["genome"]["fasta"],
        gff=config["input"]["genome"]["gff"],
    output:
        genome=config["gather_genome_data"]["fasta"],
        gff=config["gather_genome_data"]["gff"],
    run:
        shell(  # cp - copy genome fasta file from snpeff database location
            """
            cp -f {input.genome} {output.genome}
            """
        )
        shell(  # cp - copy annotation file from snpeff database location
            """
            cp -f {input.gff} {output.gff}
            """
        )


# 2b) genome data - download and aggregate genome data
# *********************************************************************
rule gatk_genome_dict:
    input:
        genome=rules.gather_genome_data.output.genome,
    output:
        genome_dict=config["gather_genome_data"]["dict"],
    log:
        config["gather_genome_data"]["dir_fasta"] + "gatk_genome_dict.log",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" CreateSequenceDictionary \
            --REFERENCE {input.genome} \
            --OUTPUT {output.genome_dict}
        """


# 2c) samtools index - index genome fasta file
# *********************************************************************s
rule samtools_index:
    input:
        genome=rules.gather_genome_data.output.genome,
    output:
        index=config["samtools_index"]["fasta_idx"],
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools faidx {input.genome}
        """


# 2d) bedops - convert genome GFF to BED
# *********************************************************************
rule bedops_gff2bed:
    input:
        gff=rules.gather_genome_data.output.gff,
    output:
        bed=config["bedops_gff2bed"]["bed"],
    params:
        feature=config["bedops_gff2bed"]["feature"],
    conda:
        "envs/bedops.yaml"
    shell:
        """
        convert2bed \
            --input=gff \
            --output=bed < {input} |\
        grep -e {params.feature} > {output}
        """


# ######################################################################
#                     Step 3 - Fastq Quality Control
# ######################################################################


# 3) trimmomatic/fastp - trim adapters and low quality bases
# *********************************************************************
rule trim_reads:
    input:
        r1=config["input"]["fastq"] + "{sample}_R1.fastq.gz",
        r2=config["input"]["fastq"] + "{sample}_R2.fastq.gz",
    output:
        r1=config["trim_reads"]["dir"] + "paired/{sample}_R1.trimmed.fastq.gz",
        r2=config["trim_reads"]["dir"] + "paired/{sample}_R2.trimmed.fastq.gz",
        r1_unpaired=config["trim_reads"]["dir"]
        + "unpaired/{sample}_R1.unpaired.fastq.gz",
        r2_unpaired=config["trim_reads"]["dir"]
        + "unpaired/{sample}_R2.unpaired.fastq.gz",
    params:
        trimmer=config["trim_reads"]["trimmer"],
        opts_trimmomatic=config["trim_reads"]["extra_trimmomatic"],
        opts_fastp=config["trim_reads"]["extra_fastp"],
    threads: config["threads"]
    log:
        log=config["trim_reads"]["dir"] + "log/trimmomatic/{sample}.log",
        json=config["trim_reads"]["dir"] + "log/fastp/{sample}.json",
        html=config["trim_reads"]["dir"] + "log/fastp/{sample}.html",
    conda:
        "envs/trimmomatic.yaml" if config["trim_reads"][
        "trimmer"
        ] == "trimmomatic" else "envs/fastp.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "------    Running Trimmomatic/Fastp    ------"
        echo "##############################################"

        if [[ "{params.trimmer}" == "fastp" ]]; then
            fastp \
                --thread {threads} \
                {params.opts_fastp} \
                --in1 {input.r1} \
                --in2 {input.r2} \
                --out1 {output.r1} \
                --out2 {output.r2} \
                --unpaired1 {output.r1_unpaired} \
                --unpaired2 {output.r2_unpaired} \
                --json {log.json} \
                --html {log.html} \
                --detect_adapter_for_pe \
                length_required=15
        else
            trimmomatic PE \
                -threads {threads} \
                {input.r1} {input.r2} \
                {output.r1} {output.r1_unpaired} \
                {output.r2} {output.r2_unpaired} \
                {params.opts_trimmomatic} \
                2> {log.log}
        fi
        """


# ######################################################################
#                      Step 4 - Map Reads to Genome
# ######################################################################


# 4a) bwa index - generate bwa genome-index files for mapping
# *********************************************************************
rule bwa_index:
    input:
        genome=rules.gather_genome_data.output.genome,
    output:
        index=touch(config["bwa"]["index"]),
    conda:
        "envs/bwa.yaml"
    shell:
        """
        echo "##############################################"
        echo "-----------    Running BWA Index    ----------"
        echo "##############################################"

        bwa index -p {output.index} {input.genome}
        """


# 4b) bwa mem - map reads to genome
# *********************************************************************
rule bwa_mem:
    input:
        reads=[
            rules.trim_reads.output.r1,
            rules.trim_reads.output.r2,
        ],
        idx=rules.bwa_index.output,
    output:
        bam=config["bwa"]["dir"] + "{sample}.bam",
    log:
        config["bwa"]["dir"] + "log/{sample}.log",
    params:
        extra=config["bwa"]["extra"],
        read_groups=r"-R '@RG\tID:{sample}\tSM:{sample}'",
    threads: config["threads"]
    conda:
        "envs/bwa.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "------------    Running BWA Mem    -----------"
        echo "##############################################"

        bwa mem \
            -t {threads} \
            {params.extra} \
            {params.read_groups} \
            {input.idx} \
            {input.reads} |\
        gatk SamFormatConverter \
            --INPUT /dev/stdin \
            --OUTPUT {output.bam} \
            2> {log}
        """


# 4c) gatk - clean sam file (remove artifacts in SAM/BAM files)
# *********************************************************************
rule gatk_clean_bam:
    input:
        bam=rules.bwa_mem.output.bam,
        genome=rules.gather_genome_data.output.genome,
    output:
        bam=config["gatk_clean_bam"]["dir"] + "{sample}.bam",
    log:
        config["gatk_clean_bam"]["dir"] + "log/{sample}.log",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input.bam}  ######"
    shell:
        """
        echo "##############################################"
        echo "--------    Running GATK CleanSam    --------"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" CleanSam \
            -R {input.genome} \
            -I {input.bam} \
            -O {output.bam} \
            2> {log}
        """


# 4d) samtools fixmate - fill in mate coordinates, ISIZE and mate related flags
# *********************************************************************
rule samtools_fixmate:
    input:
        bam=rules.gatk_clean_bam.output.bam,
    output:
        bam=config["samtools_fixmate"]["dir"] + "{sample}.bam",
    log:
        config["samtools_fixmate"]["dir"] + "log/{sample}.log",
    params:
        extra=config["samtools_fixmate"]["extra"],
    threads: config["threads"]
    conda:
        "envs/samtools.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "-------    Running Samtools Fixmate    ------"
        echo "##############################################"

        samtools fixmate \
            {input.bam} \
            {output.bam} \
            --threads {threads} \
            2> {log}
        """


# 4e) gatk MarkDuplicatesSpark - mark duplicate reads
# TODO: replace wrapper with shell command
# TODO: compare performance with sambamba and samblaster
# *********************************************************************
rule gatk_markdup:
    input:
        bam=rules.samtools_fixmate.output.bam,
    output:
        bam=config["gatk_markdup"]["dir"] + "{sample}.bam",
        metrics=config["gatk_markdup"]["metrics"] + "{sample}.metrics.txt",
    log:
        config["gatk_markdup"]["dir"] + "log/{sample}.log",
    params:
        extra=config["gatk_markdup"]["extra"],
        java_opts=config["gatk_java_opts"],
    threads: config["threads"]
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    wrapper:
        "master/bio/gatk/markduplicatesspark"


# 4f) samtools view - filter reads occurring in the core genome and index the bam file
# *********************************************************************
rule samtools_filter:
    input:
        bam=rules.gatk_markdup.output.bam,
        genome=rules.gather_genome_data.output.genome,
        core_genome=config["input"]["genome"]["core"],
    output:
        bam=config["samtools_filter"]["dir"] + "{sample}.bam",
        index=config["samtools_filter"]["dir"] + "{sample}.bam.bai",
    log:
        config["samtools_filter"]["dir"] + "log/{sample}.log",
    threads: config["threads"]
    conda:
        "envs/samtools.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input.bam}  ######"
    shell:
        """
        echo "##############################################"
        echo "--------    Running Samtools View    --------"
        echo "##############################################"

        samtools view \
            -b \
            -h \
            --threads {threads} \
            --reference {input.genome} \
            -L {input.core_genome} \
            {input.bam} \
            > {output.bam} 2> {log}

        samtools index {output.bam} {output.index}
        """


# ######################################################################
#                      Step 5 - Mapping Quality Stats
# ######################################################################


# 5a) samtools idxstats - (get mapping-quality statistics from BAM file)
# *********************************************************************
rule samtools_idxstats:
    input:
        bam=rules.samtools_filter.output.bam,
    output:
        idxstats=config["map_qual_stats"]["dir"]
        + "samtools/idxstats/{sample}.bam.idxstats.txt",
    conda:
        "envs/samtools.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "------    Running Samtools IdxStats    ------"
        echo "##############################################"

        samtools idxstats {input.bam} > {output.idxstats}
        """


# 5b) samtools flagstats - (get mapping-quality statistics from BAM file)
# *********************************************************************
rule samtools_flagstat:
    input:
        bam=rules.samtools_filter.output.bam,
    output:
        flagstat=config["map_qual_stats"]["dir"]
        + "samtools/flagstat/{sample}.bam.flagstat.txt",
    conda:
        "envs/samtools.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "------    Running Samtools Flagstat    ------"
        echo "##############################################"

        samtools flagstat {input.bam} > {output.flagstat}
        """


# 5c) samtools depth - (get mapping-quality statistics from BAM file)
# TODO: compare performance with bedtools genomecov and mosdepth
# *********************************************************************
rule samtools_depth:
    input:
        bam=rules.samtools_filter.output.bam,
    output:
        depth=config["map_qual_stats"]["dir"] + "samtools/depth/{sample}.bam.depth.txt",
    conda:
        "envs/samtools.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input}  ######"
    shell:
        """
        echo "##############################################"
        echo "------    Running Samtools Depth    ------"
        echo "##############################################"

        samtools depth {input.bam} > {output.depth}
        """


# 5d) gatk CollectInsertSizeMetrics
# *********************************************************************
rule gatk_insert_size_metrics:
    input:
        bam=rules.samtools_filter.output.bam,
        genome=rules.gather_genome_data.output.genome,
    output:
        metrics=config["map_qual_stats"]["dir"]
        + "gatk/insert_size/metrics/{sample}.metrics.txt",
        histogram=config["map_qual_stats"]["dir"]
        + "gatk/insert_size/histogram/{sample}.histogram.pdf",
    log:
        config["map_qual_stats"]["dir"] + "gatk/log/{sample}.log",
    params:
        extra=config["map_qual_stats"]["extra_gatk"],
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input.bam}  ######"
    shell:
        """
        echo "##############################################"
        echo "--  Running GATK CollectInsertSizeMetrics  --"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" CollectInsertSizeMetrics \
            {params.extra} \
            -R {input.genome} \
            -I {input.bam} \
            -O {output.metrics} \
            -H {output.histogram} \
            2> {log}
        """


# ######################################################################
#                        Step 6 - Variant Calling
# ######################################################################


# 6a) gatk HaplotypeCaller - call SNPs and indels via local re-assembly of haplotypes
# *********************************************************************
rule gatk_haplotypecaller:
    input:
        bam=rules.samtools_filter.output.bam,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        vcf=config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz",
    log:
        config["gatk_haplotypecaller"]["dir"] + "log/{sample}.log",
    params:
        java_opts=config["gatk_java_opts"],
        erc=config["gatk_haplotypecaller"]["erc"],
        extra=config["gatk_haplotypecaller"]["extra"],
    threads: config["threads"]
    conda:
        "envs/gatk.yaml"
    message:
        "######  RUNNING {rule} ON INPUT: {input.bam}  ######"
    shell:
        """
        echo "##############################################"
        echo "-----    Running GATK HaplotypeCaller    -----"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" HaplotypeCaller \
            --native-pair-hmm-threads {threads} \
            {params.extra} \
            -R {input.genome} \
            -L {input.intervals} \
            -I {input.bam} \
            -O {output.vcf} \
            2> {log}
        """


# 6b) make sample vcf map (python) - generate a map of sample names to vcf files
# *********************************************************************
rule generate_sample_name_map:
    input:
        # this input is unused but required to make snakemake wait for the gVCFs
        expand(rules.gatk_haplotypecaller.output.vcf, sample=SAMPLES),
    params:
        directory=config["gatk_haplotypecaller"]["dir"],
    output:
        config["vcf_sample_name_map"]["tsv"],
    shell:
        """
        echo "##############################################"
        echo "------    Generating VCF-Sample Map    ------"
        echo "##############################################"

        python workflow/scripts/generate_sample_vcf_map.py \
            {params.directory} \
            {output}
        """


# 6c) gatk GenomicsDBImport - merge gVCFs into one genomic database
# *********************************************************************
rule gatk_genomics_db_import:
    input:
        vcfs=expand(rules.gatk_haplotypecaller.output.vcf, sample=SAMPLES),
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
        sample_map=rules.generate_sample_name_map.output,
    output:
        dir=directory(config["gatk_genomicsdb"]["dir"]),
    log:
        config["gatk_genomicsdb"]["dir"] + "genomicsdb.log",
    params:
        java_opts=config["gatk_java_opts"],
        extra=config["gatk_genomicsdb"]["extra"],
    threads: config["threads"]
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "----    Running GATK GenomicsDBImport    ----"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" GenomicsDBImport \
            {params.extra} \
            --reader-threads {threads} \
            --genomicsdb-workspace-path {output.dir} \
            --sample-name-map {input.sample_map} \
            -L {input.intervals} \
            2> {log}
        """


# 6d) gatk GenotypeGVCFs - perform joint genotyping
# *********************************************************************
rule gatk_genotype_gvcfs:
    input:
        db=rules.gatk_genomics_db_import.output.dir,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        vcf=config["gatk_genotype_gvcfs"]["dir"] + "genotypes.vcf.gz",
    log:
        config["gatk_genotype_gvcfs"]["dir"] + "genotypes.log",
    params:
        extra=config["gatk_genotype_gvcfs"]["extra"],
        java_opts=config["gatk_java_opts"],
        threads=config["threads"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "-----     Running GATK GenotypeGVCFs     -----"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" GenotypeGVCFs \
            {params.extra} \
            -R {input.genome} \
            -V gendb://{input.db} \
            -L {input.intervals} \
            -O {output.vcf} \
            2> {log}
        """


# ######################################################################
#                      Step 7 - Variant Filtering
# ######################################################################


# 7a) gatk VariantSeparate - separate snps and indels
# TODO: consider seleting mixed sites and multiallelic sites
# *********************************************************************
rule gatk_split_variants:
    input:
        vcf=rules.gatk_genotype_gvcfs.output.vcf,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        snps=config["gatk_var_split"]["dir"] + "snps.vcf.gz",
        indels=config["gatk_var_split"]["dir"] + "indels.vcf.gz",
    log:
        snps=config["gatk_var_split"]["dir"] + "snps.log",
        indels=config["gatk_var_split"]["dir"] + "indels.log",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "-----    Running GATK SelectVariants     -----"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" SelectVariants \
            -R {input.genome} \
            -V {input.vcf} \
            -O {output.snps} \
            --select-type-to-include SNP \
            2> {log.snps}
        gatk --java-options "{params.java_opts}" SelectVariants \
            -R {input.genome} \
            -V {input.vcf} \
            -O {output.indels} \
            --select-type-to-include INDEL \
            2> {log.indels}
        """


# 7b) gatk VariantFiltrationHard - snps and indels
# *********************************************************************
rule gatk_filter_hard:
    input:
        snps=rules.gatk_split_variants.output.snps,
        indels=rules.gatk_split_variants.output.indels,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        snps=config["gatk_filter_hard"]["dir"] + "snps_filtered.vcf.gz",
        indels=config["gatk_filter_hard"]["dir"] + "indels_filtered.vcf.gz",
    log:
        snps=config["gatk_filter_hard"]["dir"] + "snps.log",
        indels=config["gatk_filter_hard"]["dir"] + "indels.log",
    params:
        java_opts=config["gatk_java_opts"],
        extra_snps=config["gatk_filter_hard"]["extra_indels"],
        extra_indels=config["gatk_filter_hard"]["extra_indels"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "----    Running GATK VariantFiltration    ----"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" VariantFiltration \
            {params.extra_snps} \
            -R {input.genome} \
            -V {input.snps} \
            -O {output.snps} \
            2> {log.snps}
        gatk --java-options "{params.java_opts}" VariantFiltration \
            {params.extra_indels} \
            -R {input.genome} \
            -V {input.indels} \
            -O {output.indels} \
            2> {log.indels}
        """


# 7c) gatk MergeVcfs - merge snps and indels
# *********************************************************************
rule gatk_merge_vcfs:
    input:
        snps=rules.gatk_filter_hard.output.snps,
        indels=rules.gatk_filter_hard.output.indels,
    output:
        vcf=config["gatk_merge_vcfs"]["dir"] + "merged.vcf.gz",
    log:
        config["gatk_merge_vcfs"]["dir"] + "merged.log",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "---------   Running GATK MergeVcfs   ---------"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" MergeVcfs \
            -I {input.snps} \
            -I {input.indels} \
            -O {output.vcf} \
            2> {log}
        """


# 7d) gatk FilterPassVariants - exclude variants that failed filters
# *********************************************************************
rule gatk_filter_pass:
    input:
        vcf=rules.gatk_merge_vcfs.output.vcf,
    output:
        vcf=config["gatk_filter_pass"]["dir"] + "pass.vcf.gz",
    log:
        config["gatk_filter_pass"]["dir"] + "pass.log",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "envs/gatk.yaml"
    shell:
        """
        echo "##############################################"
        echo "-------   Running GATK FilterVcfPass   -------"
        echo "##############################################"

        gatk --java-options "{params.java_opts}" SelectVariants \
            -V {input.vcf} \
            -O {output.vcf} \
            --exclude-filtered \
            2> {log}
        """


# ######################################################################
#                      Step 8 - Variant Annotation
# ######################################################################


# 8a) snpEff annotate - variant annotation and functional effect prediction
# *********************************************************************
rule snpeff_annotate_variants:
    input:
        vcf=rules.gatk_filter_pass.output.vcf,
    output:
        vcf=config["snpeff"]["dir"] + "annotated.vcf.gz",
    log:
        config["snpeff"]["dir"] + "snpeff.log",
    params:
        config=config["snpeff"]["config"],
        extra=config["snpeff"]["extra_snpeff"],
        database=config["snpeff"]["database"],
    conda:
        "envs/snpeff.yaml"
    shell:
        """
        echo "##############################################"
        echo "--------   Running SnpEff Annotate   --------"
        echo "##############################################"

        snpEff {params.extra} \
            -config {params.config} \
            {params.database} \
            {input.vcf} | gzip > {output.vcf}
        """


# 8b) SnpSift - extract vcf fields and calculate allele frequencies
# *********************************************************************
rule snpsift_extract_variants:
    input:
        vcf=rules.snpeff_annotate_variants.output.vcf,
    output:
        variants=config["snpeff"]["dir"] + "annotated.tsv",
    log:
        config["snpeff"]["dir"] + "snpsift.log",
    params:
        extra=config["snpeff"]["extra_snpsift"],
    conda:
        "envs/snpsift.yaml"
    shell:
        """
        echo "##############################################"
        echo "--------   Running SnpSift Extract   --------"
        echo "##############################################"

        SnpSift extractFields \
            {input.vcf} \
            {params.extra} |\
        awk '
            BEGIN {{ FS=OFS="\\t" }}
            NR == 1 {{
                allelFreq1 = "AF_REF"
                allelFreq2 = "AF_ALT"
            }}
            NR > 1 {{
                split($12,a,",")
                sum = a[1] + a[2]
                if ( sum ) {{
                    allelFreq1 = a[1] / sum
                    allelFreq2 = a[2] / sum
                }}
                else {{
                    allelFreq1 = 0
                    allelFreq2 = 0
                }}
            }}
            {{ print $0, allelFreq1, allelFreq2 }}
            ' |\
        sed -e 's/ANN\\[\\*\\]\\.//g' | sed -e 's/GEN\\[\\*\\]\\.//g' > {output.variants}
        """
