# #####################################################################
#   A Snakemake pipeline for variant calling from illumina sequences
# #####################################################################

# TODO: include snakemake reports - https://snakemake.readthedocs.io/en/v5.32.0/snakefiles/reporting.html#snakefiles-reports
# TODO: abide by https://snakemake.readthedocs.io/en/v5.32.0/snakefiles/deployment.html#

# table of contents
# *********************************************************************
# step 1 - output files
# - 1) rule all - gather all output files

# step 2 - gather genome data
# - 2a) rule gather_genome_data - download and aggregate genome data
# - 2b) rule gatk_genome_dict - create genome dictionary
# - 2c) rule samtools_index - index genome fasta file
# - 2d) rule bedops_gff2bed - convert genome annotation gff to bed

# step 3 - quality control
# -  3) rule trimmomatic - trim adapters and low quality bases

# step 4 - map reads to genome
# - 4a) rule bwa_index - generate bwa genome-index files for mapping
# - 4b) rule bwa_mem - map reads to genome
# - 4c) rule gatk_clean - clean sam file (remove artifacts in SAM/BAM files)
# - 4d) rule gatk_markdup - mark duplicates
# - 4e) rule samtools_view - filter reads occuring in the core genome and index the bam file
# - 4f) rule samtools_idxstats - count reads in each chromosome
# - 4g) rule samtools_flagstats - count reads in each chromosome
# - 4h) rule gatk_insert_size_metrics - collect insert size metrics
# - 4i) rule gatk_haplotypecaller - call variants

# step 5 - variant calling
# - 5a) rule gatk_genomics_db_import - merge gVCFs into one genomic database
# - 5b) make sample vcf map (python) - generate a map of sample names to vcf files
# - 5c) gatk GenomicsDBImport - merge gVCFs into one genomic database
# - 5d) gatk GenotypeGVCFs - perform joint genotyping

# step 6 - variant filtering
# 6a) gatk VariantFiltration - hard filter variants


# ######################################################################
#                               DEPENDENCIES
# ######################################################################
# configuration file
configfile: "config/config.yaml"


# start my generating a list of samples. This code assumes that all fastq files
# have the format:
#  - SampleName_R1.fastq.gz
#  - SampleName_R2.fastq.gz

# If not, they might have the format:
#  - SampleName_S1_L001_R1_001.fastq.gz
#  - SampleName_S1_L001_R2_001.fastq.gz

# In this case, rename the files running the following python script in your terminal,
# while at the top level of this project:
#  - python3 workflow/fastq_rename.py
(SAMPLES,) = glob_wildcards(config["input"]["fastq"] + "{sample}_R1.fastq.gz")


# ######################################################################
#               STEP 1 - PREPARE A LIST OF ALL OUTPUT FILES
# ######################################################################


# 1) gather all output files
# *********************************************************************
rule all:
    input:
        # ------------------------------------
        # gather_genome_data
        config["gather_genome_data"]["fasta"],
        config["gather_genome_data"]["gff"],
        # ------------------------------------
        # genome_dict
        config["gather_genome_data"]["dict"],
        # config["gather_genome_data"]["regions"],
        # ------------------------------------
        # samtools_index
        config["samtools_index"]["fasta_idx"],
        # ------------------------------------        
        # bedops_gff2bed
        config["bedops_gff2bed"]["bed"],
        # ------------------------------------
        # trimmomaticS,
        expand(config["trimmomatic"]["dir"] + "{sample}_R1.fastq.gz", sample=SAMPLES),
        expand(config["trimmomatic"]["dir"] + "{sample}_R2.fastq.gz", sample=SAMPLES),
        expand(
            config["trimmomatic"]["dir"] + "{sample}_R1.unpaired.fastq.gz",
            sample=SAMPLES,
        ),
        expand(
            config["trimmomatic"]["dir"] + "{sample}_R2.unpaired.fastq.gz",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # bwa_index
        config["bwa"]["index"],
        # ------------------------------------
        # bwa_mem
        expand(config["bwa"]["dir"] + "{sample}.bam", sample=SAMPLES),
        # ------------------------------------
        # gatk_clean
        expand(config["gatk_clean"]["dir"] + "{sample}.bam", sample=SAMPLES),
        # ------------------------------------
        # gatk_markdup
        expand(config["gatk_markdup"]["dir"] + "{sample}.bam", sample=SAMPLES),
        expand(
            config["gatk_markdup"]["metrics"] + "{sample}.metrics.txt", sample=SAMPLES
        ),
        # ------------------------------------
        # samtools
        expand(config["samtools_view"]["dir"] + "{sample}.bam", sample=SAMPLES),
        expand(config["samtools_view"]["dir"] + "{sample}.bam.bai", sample=SAMPLES),
        # ------------------------------------
        # samtools_idxstats & samtools_flagstats
        expand(
            config["samtools_stats"]["dir"] + "{sample}.bam.idxstats.txt",
            sample=SAMPLES,
        ),
        expand(
            config["samtools_stats"]["dir"] + "{sample}.bam.flagstat.txt",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # gatk_insert_size_metrics
        expand(
            config["gatk_insert_size"]["dir_metrics"] + "{sample}.metrics.txt",
            sample=SAMPLES,
        ),
        expand(
            config["gatk_insert_size"]["dir_histogram"] + "{sample}.histogram.pdf",
            sample=SAMPLES,
        ),
        # ------------------------------------
        # gatk_realign
        expand(
            config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # gatk_haplotypecaller
        expand(
            config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # generate_sample_name_map
        config["vcf_sample_name_map"]["tsv"],
        # ------------------------------------
        # gatk_genomics_db_import
        config["gatk_genomicsdb"]["dir"],
        # ------------------------------------
        # gatk_genotype_gvcfs
        expand(
            config["gatk_genotype_gvcfs"]["dir"] + "genotypes.vcf.gz", sample=SAMPLES
        ),
        # ------------------------------------
        # gatk_variant_filtration
        config["gatk_var_filter_hard"]["dir"] + "filtered.vcf.gz",


# ######################################################################
#                      STEP 2 - GATHER GENOME DATA
# ######################################################################

# TODO: include a log file for each rule
# TODO: include temp dir for scratch space


# 2a) genome data - download genome data
# *********************************************************************
rule gather_genome_data:
    input:
        genome=config["input"]["genome"]["fasta"],
        gff=config["input"]["genome"]["gff"],
    output:
        genome=config["gather_genome_data"]["fasta"],
        gff=config["gather_genome_data"]["gff"],
    run:
        shell(  # cp - copy genome fasta file from snpeff database location
            """
            cp -f {input.genome} {output.genome}
            """
        )
        shell(  # cp - copy annotation file from snpeff database location
            """
            cp -f {input.gff} {output.gff}
            """
        )


# 2b) genome data - download and aggregate genome data
# *********************************************************************
rule gatk_genome_dict:
    input:
        genome=rules.gather_genome_data.output.genome,
    output:
        genome_dict=config["gather_genome_data"]["dict"],
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" CreateSequenceDictionary \
        --REFERENCE {input.genome} \
        --OUTPUT {output.genome_dict}
        """


# 2c) samtools index - index genome fasta file
# *********************************************************************s
rule samtools_index:
    input:
        rules.gather_genome_data.output.genome,
    output:
        config["samtools_index"]["fasta_idx"],
    conda:
        "env/samtools.yaml"
    shell:
        """
        samtools faidx {input}
        """


# 2d) bedops - convert genome GFF to BED
# *********************************************************************
rule bedops_gff2bed:
    input:
        rules.gather_genome_data.output.gff,
    output:
        config["bedops_gff2bed"]["bed"],
    params:
        feature=config["bedops_gff2bed"]["feature"],
    conda:
        "env/bedops.yaml"
    shell:
        """
        convert2bed --input=gff --output=bed < {input} | \
            grep -e {params.feature} > {output}
        """


# ######################################################################
#                        STEP 3 - QUALITY CONTROL
# ######################################################################


# 3) trimmomatic - trim adapters and low quality bases
# TODO: 1. add support for single end mode
# TODO: 2. review the parameters
# TODO: 4. switch to universal thread count from config file
# *********************************************************************
rule trimmomatic:
    input:
        r1=config["input"]["fastq"] + "{sample}_R1.fastq.gz",
        r2=config["input"]["fastq"] + "{sample}_R2.fastq.gz",
    output:
        r1=config["trimmomatic"]["dir"] + "{sample}_R1.fastq.gz",
        r2=config["trimmomatic"]["dir"] + "{sample}_R2.fastq.gz",
        r1_unpaired=config["trimmomatic"]["dir"] + "{sample}_R1.unpaired.fastq.gz",
        r2_unpaired=config["trimmomatic"]["dir"] + "{sample}_R2.unpaired.fastq.gz",
    params:
        trimmer=config["trimmomatic"]["trimmer"],
    threads: config["threads"]
    log:
        config["trimmomatic"]["dir"] + "log/{sample}.log",
    conda:
        "env/trimmomatic.yaml"
    shell:
        """
        trimmomatic PE \
            -threads {threads} \
            {input.r1} {input.r2} \
            {output.r1} {output.r1_unpaired} \
            {output.r2} {output.r2_unpaired} \
            {params.trimmer} \
            2> {log}
        """


# ######################################################################
#                      STEP 4 - MAP READS TO GENOME
# ######################################################################


# 4a) bwa - generate bwa genome-index files for mapping
# *********************************************************************
rule bwa_index:
    input:
        genome=rules.gather_genome_data.output.genome,
    output:
        index=touch(config["bwa"]["index"]),
    conda:
        "env/bwa.yaml"
    shell:
        """
        bwa index -p {output.index} {input.genome}
        """


# 4b) bwa mem - map reads to genome
# TODO: replace wrapper with shell command
# *********************************************************************
rule bwa_mem:
    input:
        reads=[
            rules.trimmomatic.output.r1,
            rules.trimmomatic.output.r2,
        ],
        idx=rules.bwa_index.output,
    output:
        config["bwa"]["dir"] + "{sample}.bam",
    log:
        config["bwa"]["log"] + "{sample}.log",
    params:
        extra=r"-R '@RG\tID:{sample}\tSM:{sample}'",
    threads: config["threads"]
    wrapper:
        "master/bio/bwa/mem"


# 4c) gatk - clean sam file (remove artifacts in SAM/BAM files)
# *********************************************************************
rule gatk_clean:
    input:
        bam=rules.bwa_mem.output,
        genome=rules.gather_genome_data.output.genome,
    output:
        clean=config["gatk_clean"]["dir"] + "{sample}.bam",
    params:
        java_opts=config["gatk_java_opts"],
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" CleanSam \
            -R {input.genome} \
            -I {input.bam} \
            -O {output.clean}
        """


# 4d) gatk - mark duplicates
# TODO: replace wrapper with shell command
# TODO: compare performance with sambamba markdup
# *********************************************************************
rule gatk_markdup:
    input:
        bam=rules.gatk_clean.output.clean,
    output:
        bam=config["gatk_markdup"]["dir"] + "{sample}.bam",
        metrics=config["gatk_markdup"]["metrics"] + "{sample}.metrics.txt",
    log:
        config["gatk_markdup"]["log"] + "{sample}.log",
    params:
        extra="--remove-all-duplicates",
        java_opts=config["gatk_java_opts"],
    threads: config["threads"]
    wrapper:
        "master/bio/gatk/markduplicatesspark"


# 4e) samtools - filter reads occuring in the core genome and index the bam file
# *********************************************************************
rule samtools_view:
    input:
        bam=rules.gatk_markdup.output.bam,
        genome=rules.gather_genome_data.output.genome,
        core_genome=config["input"]["genome"]["core"],
    output:
        bam=config["samtools_view"]["dir"] + "{sample}.bam",
        index=config["samtools_view"]["dir"] + "{sample}.bam.bai",
    log:
        config["samtools_view"]["log"] + "{sample}.log",
    threads: config["threads"]
    conda:
        "env/samtools.yaml"
    shell:
        """
        samtools view \
            -b \
            -h \
            -@ {threads} \
            -T {input.genome} \
            -L {input.core_genome} \
            {input.bam} \
            > {output.bam}
        samtools index {output.bam} {output.index}
        """


# 4f) samtools - idxstats (get mapping-quality statistics from BAM file)
# *********************************************************************
rule samtools_idxstats:
    input:
        rules.samtools_view.output.bam,
    output:
        config["samtools_stats"]["dir"] + "{sample}.bam.idxstats.txt",
    conda:
        "env/samtools.yaml"
    shell:
        """
        samtools idxstats {input} > {output}
        """


# 4g) samtools - flagstats (get mapping-quality statistics from BAM file)
# *********************************************************************
rule samtools_flagstat:
    input:
        rules.samtools_view.output.bam,
    output:
        config["samtools_stats"]["dir"] + "{sample}.bam.flagstat.txt",
    conda:
        "env/samtools.yaml"
    shell:
        """
        samtools flagstat {input} > {output}
        """


# TODO: add samtools stats and samtools depth


# 4h) gatk CollectInsertSizeMetrics
# *********************************************************************
rule gatk_insert_size_metrics:
    input:
        bam=rules.samtools_view.output.bam,
        genome=rules.gather_genome_data.output.genome,
    output:
        metrics=config["gatk_insert_size"]["dir_metrics"] + "{sample}.metrics.txt",
        histogram=config["gatk_insert_size"]["dir_histogram"] + "{sample}.histogram.pdf",
    log:
        config["gatk_insert_size"]["log"] + "{sample}.log",
    params:
        extra="",
        java_opts=config["gatk_java_opts"],
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" CollectInsertSizeMetrics \
            {params.extra} \
            -R {input.genome} \
            -I {input.bam} \
            -O {output.metrics} \
            -H {output.histogram}
        """


# ######################################################################
#                        STEP 5 - VARIANT CALLING
# ######################################################################


# 5a) gatk HaplotypeCaller - generate gVCFs
# TODO: check that HaplotypeCaller is actually using these parameters
# *********************************************************************
rule gatk_haplotypecaller:
    input:
        bam=rules.samtools_view.output.bam,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        vcf=config["gatk_haplotypecaller"]["dir"] + "{sample}.vcf.gz",
    log:
        config["gatk_haplotypecaller"]["log"] + "{sample}.log",
    params:
        java_opts=config["gatk_java_opts"],
        erc=config["gatk_haplotypecaller"]["erc"],
        extra=config["gatk_haplotypecaller"]["extra"],
    threads: config["threads"]
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" HaplotypeCaller \
            --native-pair-hmm-threads {threads} \
            {params.extra} \
            -R {input.genome} \
            -L {input.intervals} \
            -I {input.bam} \
            -O {output.vcf}
        """


# 5b) make sample vcf map (python) - generate a map of sample names to vcf files
# *********************************************************************
rule generate_sample_name_map:
    input:
        # while this is not used, it is required to make snakemake wait
        # for the gVCFs to be generated
        expand(rules.gatk_haplotypecaller.output.vcf, sample=SAMPLES),
    params:
        directory=config["gatk_haplotypecaller"]["dir"],
    output:
        config["vcf_sample_name_map"]["tsv"],
    shell:
        "python workflow/scripts/generate_sample_vcf_map.py {params.directory} {output}"


# 5c) gatk GenomicsDBImport - merge gVCFs into one genomic database
# *********************************************************************
rule gatk_genomics_db_import:
    input:
        vcfs=expand(rules.gatk_haplotypecaller.output.vcf, sample=SAMPLES),
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
        sample_map=rules.generate_sample_name_map.output,
    output:
        dir=directory(config["gatk_genomicsdb"]["dir"]),
    log:
        config["gatk_genomicsdb"]["dir"] + "genomicsdb.log",
    params:
        java_opts=config["gatk_java_opts"],
        extra=config["gatk_genomicsdb"]["extra"],
    threads: config["threads"]
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" GenomicsDBImport \
            {params.extra} \
            --reader-threads {threads} \
            --genomicsdb-workspace-path {output.dir} \
            --sample-name-map {input.sample_map} \
            -L {input.intervals}
        """


# 5d) gatk GenotypeGVCFs - perform joint genotyping
# *********************************************************************
rule gatk_genotype_gvcfs:
    input:
        db=rules.gatk_genomics_db_import.output.dir,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        vcf=config["gatk_genotype_gvcfs"]["dir"] + "genotypes.vcf.gz",
    log:
        config["gatk_genotype_gvcfs"]["dir"] + "genotypes.log",
    params:
        extra=config["gatk_genotype_gvcfs"]["extra"],
        java_opts=config["gatk_java_opts"],
        threads=config["threads"],
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" GenotypeGVCFs \
            {params.extra} \
            -R {input.genome} \
            -V gendb://{input.db} \
            -L {input.intervals} \
            -O {output.vcf}
        """


# ######################################################################
#                       STEP 6 - VARIANT FILTERING
# ######################################################################


# 6a) gatk VariantFiltration - hard-filter variants
# *********************************************************************
rule gatk_var_filter_hard:
    input:
        vcf=rules.gatk_genotype_gvcfs.output.vcf,
        genome=rules.gather_genome_data.output.genome,
        intervals=config["input"]["genome"]["core"],
    output:
        vcf=config["gatk_var_filter_hard"]["dir"] + "filtered.vcf.gz",
    log:
        config["gatk_var_filter_hard"]["dir"] + "filtered.log",
    params:
        java_opts=config["gatk_java_opts"],
        extra=config["gatk_var_filter_hard"]["extra"],
    conda:
        "env/gatk.yaml"
    shell:
        """
        gatk --java-options "{params.java_opts}" VariantFiltration \
            {params.extra} \
            -R {input.genome} \
            -V {input.vcf} \
            -O {output.vcf}
        """
